{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574837fc",
   "metadata": {
    "id": "574837fc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, shutil\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import splitfolders\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7508e",
   "metadata": {
    "id": "56b7508e"
   },
   "source": [
    "## MRL-Eye Dataset\n",
    "\n",
    "the dataset consists of 84,898 images from 37 subjects \n",
    "\n",
    "Image shape 86 x 86 ; Label : eye state [0 - closed, 1 - open]\n",
    "\n",
    "Eye images were obtained using the eye detector based on the histogram of oriented gradients (HOG) combined with the SVM classifier\n",
    "\n",
    "Source: http://mrl.cs.vsb.cz/eyedataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6739e29",
   "metadata": {
    "id": "a6739e29"
   },
   "source": [
    "# Data Preprocessing and splitting into train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0948af7",
   "metadata": {
    "id": "d0948af7"
   },
   "outputs": [],
   "source": [
    "# dir = \"Datasets\"\n",
    "# open_eyes = glob.glob(dir + \"/mrlEyes_2018_01/*/*_*_*_*_1_*_*_*.png\",recursive=True)\n",
    "# closed_eyes = glob.glob(dir + \"/mrlEyes_2018_01/*/*_*_*_*_0_*_*_*.png\",recursive=True)\n",
    "\n",
    "# Path(dir+\"/MRL\").mkdir(parents=True, exist_ok=True)\n",
    "# Path(dir+\"/MRL/Open_Eyes\").mkdir(parents=True, exist_ok=True)\n",
    "# Path(dir+\"/MRL/Closed_Eyes\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for file in open_eyes:\n",
    "#     shutil.copy(file, dir+\"/MRL/Open_Eyes\")\n",
    "    \n",
    "# for file in closed_eyes:\n",
    "#     shutil.copy(file, dir+\"/MRL/Closed_Eyes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e59870",
   "metadata": {
    "id": "86e59870",
    "outputId": "4887b974-593b-425a-d6b1-207e9cfbf29b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 84898 files [01:30, 935.13 files/s] \n"
     ]
    }
   ],
   "source": [
    "# input_dir = \"Datasets/MRL\"\n",
    "# output_dir = \"Datasets/MRL\"\n",
    "\n",
    "# splitfolders.ratio(input_dir, output=output_dir, seed=1337, ratio=(0.6, 0.2,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa35ee6",
   "metadata": {
    "id": "2aa35ee6"
   },
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583f70b2",
   "metadata": {
    "id": "583f70b2"
   },
   "outputs": [],
   "source": [
    "dir = \"Datasets/MRL\"\n",
    "labels = {\"Closed_Eyes\":0,\"Open_Eyes\":1}\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a043ba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images = []\n",
    "# X = []\n",
    "# y = []\n",
    "# sample = cv2.imread('sample.png',cv2.IMREAD_GRAYSCALE)\n",
    "# norm_image = cv2.normalize(sample, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "# rgb = cv2.cvtColor(norm_image,cv2.COLOR_GRAY2RGB)\n",
    "# img = cv2.resize(rgb, (img_size,img_size))            \n",
    "# images.append([img,0])\n",
    "# images.append([img,0])\n",
    "\n",
    "# for features, label in images:\n",
    "#     X.append(features)\n",
    "#     y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00488287",
   "metadata": {
    "id": "00488287"
   },
   "outputs": [],
   "source": [
    "def create_dataset(folder): \n",
    "    # load images from the folder\n",
    "    # resize the images\n",
    "    # normalise the data\n",
    "    \n",
    "    labels = {\"Closed_Eyes\":0,\"Open_Eyes\":1}\n",
    "    img_size = 224\n",
    "    images = []\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for label in labels:\n",
    "        img_class = labels[label]\n",
    "        path = folder+\"/\"+label\n",
    "        for filename in os.listdir(path):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(path,filename), cv2.IMREAD_GRAYSCALE)\n",
    "                norm_img = cv2.normalize(img, None, alpha=0, beta=1, \n",
    "                                           norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                rgb = cv2.cvtColor(norm_img,cv2.COLOR_GRAY2RGB)\n",
    "                img = cv2.resize(rgb, (img_size,img_size))            \n",
    "                images.append([img,img_class])\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "      \n",
    "    random.shuffle(images)\n",
    "\n",
    "    # split shuffled images and labels \n",
    "    for features, label in images:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "\n",
    "    # reshape images\n",
    "    X = np.array(X).reshape(-1,img_size,img_size,3)\n",
    "    y = np.array(y)\n",
    "        \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058fab3",
   "metadata": {
    "id": "9058fab3"
   },
   "source": [
    "# Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f3c79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test, y_test) = create_dataset(dir+\"/test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b82ec68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16981, 224, 224, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b056584",
   "metadata": {
    "id": "2b056584",
    "outputId": "3cfc29a3-7281-4019-e356-cea41362d265",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check data by plotting first 20 images\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.xlabel(y_test[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e019d",
   "metadata": {
    "id": "4a9e019d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train) = create_dataset(dir+\"/train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_val, y_val) = create_dataset(dir+\"/val\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f74b838",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0da7701eb996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Save data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('X_test.pickle','wb') as handle:\n",
    "    pickle.dump(X_test, handle)\n",
    "    \n",
    "with open('y_test.pickle','wb') as handle:\n",
    "    pickle.dump(y_test, handle)\n",
    "    \n",
    "\n",
    "    \n",
    "with open('X_train.pickle','wb') as handle:\n",
    "    pickle.dump(X_train, handle)\n",
    "    \n",
    "with open('y_train.pickle','wb') as handle:\n",
    "    pickle.dump(y_train, handle)\n",
    "    \n",
    "\n",
    "    \n",
    "with open('X_val.pickle','wb') as handle:\n",
    "    pickle.dump(X_val, handle)\n",
    "    \n",
    "with open('y_val.pickle','wb') as handle:\n",
    "    pickle.dump(y_val, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "edd4557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('X_test.pickle','wb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "    \n",
    "with open('y_test.pickle','wb') as handle:\n",
    "    y_test = pickle.load(handle)\n",
    "    \n",
    "\n",
    "    \n",
    "with open('X_train.pickle','wb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "    \n",
    "with open('y_train.pickle','wb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "    \n",
    "\n",
    "    \n",
    "with open('X_val.pickle','wb') as handle:\n",
    "    X_val = pickle.load(handle)\n",
    "    \n",
    "with open('y_val.pickle','wb') as handle:\n",
    "    y_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac743a",
   "metadata": {
    "id": "ecac743a"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70bcbdff",
   "metadata": {
    "id": "70bcbdff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RBU17KzBBI3C",
   "metadata": {
    "id": "RBU17KzBBI3C"
   },
   "outputs": [],
   "source": [
    "model = MobileNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BAzgfszcDGfk",
   "metadata": {
    "id": "BAzgfszcDGfk"
   },
   "outputs": [],
   "source": [
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[-4].output\n",
    "\n",
    "flat_layer = layers.Flatten()(base_output)\n",
    "final_output = layers.Dense(1)(flat_layer)\n",
    "final_output = layers.Activation('sigmoid')(final_output)\n",
    "\n",
    "new_model = keras.Model(inputs = base_input, outputs = final_output)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "UlthnjKoEV_B",
   "metadata": {
    "id": "UlthnjKoEV_B"
   },
   "outputs": [],
   "source": [
    "new_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6wfmkvMPE0gz",
   "metadata": {
    "id": "6wfmkvMPE0gz"
   },
   "outputs": [],
   "source": [
    "new_model.fit(X_train, y_train, epochs=2, validation_data=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "FHd3DIDZFpkz",
   "metadata": {
    "id": "FHd3DIDZFpkz"
   },
   "outputs": [],
   "source": [
    "new_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aRWHSM5FFwWT",
   "metadata": {
    "id": "aRWHSM5FFwWT"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('dl_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "di_GSLFXGfHj",
   "metadata": {
    "id": "di_GSLFXGfHj"
   },
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oVlmgnxNGes4",
   "metadata": {
    "id": "oVlmgnxNGes4"
   },
   "outputs": [],
   "source": [
    "test_img = cv2.imread('path', cv2.IMREAD_GRAYSCALE)\n",
    "rgb = cv2.cvtColor(test_img,cv2.COLOR_GRAY2RGB) #convert to RGB\n",
    "new_array = cv2.resize(rgb,(img_size,img_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qTg1tdSyBTFk",
   "metadata": {
    "id": "qTg1tdSyBTFk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(...)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(...)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DD_MRL_Inceptionv3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
